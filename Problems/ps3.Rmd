#######################
## Problem Set 3     ##
#######################

**Due Date**: [Insert due date]  
**Submission**: [https://canvas.northwestern.edu/courses/245562/assignments/1676747](https://canvas.northwestern.edu/courses/245562/assignments/1676747)

**Instructions**: 
- Show all work for theoretical problems.
- Include complete, well-commented R code for applied problems.
- Submit knitted document with all outputs.

---

####################
## Problem 1      ##
####################

**1a.** In a multiple regression model, $Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \epsilon$, interpret $\beta_1$ in your own words.

**1b.** Consider the slides' example of terrorism incidents predicted by Trump vote share and 2012 margin. If the estimated equation is:
$$\text{Terrorism} = 10 - 0.2 \times \text{TrumpShare} + 0.1 \times \text{D12Margin}$$
Interpret what happens to predicted terrorism incidents when:
- TrumpShare increases by 5 percentage points, holding D12Margin constant.
- D12Margin decreases by 3 percentage points, holding TrumpShare constant.

**1c.** The slides show that in multivariate regression, $\beta_1$ represents the expected change in Y when $X_1$ increases by 1 unit, *with all other variables held constant*. Why is the "all other variables held constant" condition crucial for interpreting $\beta_1$ as a partial effect?

---

####################
## Problem 2      ##
####################

**Theoretical Proof with Guided Steps**

The Conditional Expectation Function (CEF) has a key property: it is the best predictor of Y given X in the mean-squared error sense.

Let $m(X)$ be any function of X used to predict Y. The mean-squared error (MSE) is defined as:
$$MSE(m) = E[(Y - m(X))^2]$$

**2a.** Show that for any predictor $m(X)$, the MSE can be decomposed as:
$$E[(Y - m(X))^2] = E[(Y - E[Y|X])^2] + E[(E[Y|X] - m(X))^2]$$

*Hint: Start with $Y - m(X) = (Y - E[Y|X]) + (E[Y|X] - m(X))$, then expand the square.*

**2b.** Using the decomposition from 2a, explain why the CEF ($E[Y|X]$) minimizes MSE among all possible predictors $m(X)$.

**2c.** Connect this proof to the lecture discussion about why we can't improve the CEF by adding something that depends on X. What does this imply about the relationship between the CEF error ($Y - E[Y|X]$) and X?

---

####################
## Problem 3      ##
####################

**Applied Analysis: Voter Turnout in U.S. States**

Install and load the required data:

```{r load-data, eval=FALSE}
install.packages("poliscidata")
library(poliscidata)
library(tidyverse)

# Clean and prepare the data
states_data <- states %>%
  select(state, vep12_turnout, prcapinc, religiosity, over64) %>%
  filter(!is.na(vep12_turnout), !is.na(prcapinc)) %>%
  mutate(income_thousands = prcapinc / 1000)
```

**3a. Bivariate Regression and CEF Visualization**

Run a bivariate regression predicting voter turnout (`vep12_turnout`) based on income (`prcapinc` or `income_thousands`).

```{r 3a-code, eval=FALSE}
# Your code here
turnout_bivariate <- lm(vep12_turnout ~ income_thousands, data = states_data)
summary(turnout_bivariate)
```

Create a visualization that shows:
1. The raw data points
2. The BLP (linear regression line)
3. A LOESS curve to approximate the true CEF
4. Compare the two curves. Does the relationship appear linear?

**Questions for 3a:**
1. Interpret the slope coefficient from the bivariate regression.
2. Based on the visualization, does the BLP appear to be a good approximation of the CEF? Explain.
3. Calculate and interpret R-squared.

**3b. Multivariate Regression Analysis**

Now run a multivariate regression predicting voter turnout based on income (`prcapinc`), religiosity (`religiosity`), and age distribution (`over64`).

```{r 3b-code, eval=FALSE}
# Your code here
turnout_multivariate <- lm(vep12_turnout ~ income_thousands + religiosity + over64, 
                           data = states_data)
summary(turnout_multivariate)
```

**Questions for 3b:**
1. Interpret each coefficient in the multivariate model.
2. How does the coefficient for income change from the bivariate to multivariate model? What might explain this change?
3. Calculate the predicted voter turnout for a state with: income = $50,000, religiosity = 50, over64 = 15%.

**3c. Model Comparison and CEF Evaluation**

Compare the two models:

```{r 3c-code, eval=FALSE}
# Model comparison
library(modelsummary)
models <- list("Bivariate" = turnout_bivariate, 
               "Multivariate" = turnout_multivariate)
modelsummary(models, stars = TRUE, output = "markdown")

# Calculate and compare R-squared
cat("Bivariate R-squared:", summary(turnout_bivariate)$r.squared, "\n")
cat("Multivariate R-squared:", summary(turnout_multivariate)$r.squared, "\n")
```

**Questions for 3c:**
1. Which model has better fit? Does adding variables substantially improve the model?
2. In the multivariate model, are all variables jointly significant? (Hint: Check the F-test)
3. Based on the lecture discussion about when BLP equals CEF, do you think the multivariate linear model adequately captures the true CEF? What evidence supports your conclusion?

**3d. Diagnostics and Assumptions**

Check key regression assumptions:

```{r 3d-code, eval=FALSE}
# Diagnostic plots
par(mfrow = c(2, 2))
plot(turnout_multivariate)

# Check for non-linearity (component + residual plot)
library(car)
crPlots(turnout_multivariate)
```

**Questions for 3d:**
1. Do the residual plots suggest any violations of linear regression assumptions?
2. The component + residual plots show the relationship between each predictor and the outcome, partialling out other variables. Do these relationships appear linear?
3. If you observed non-linearity in the income-turnout relationship, how might you modify the model to better approximate the CEF? (Consider transformations or polynomial terms)

---

####################
## Problem 4      ##
####################

**Synthesis: Connecting Theory and Application**

**4a.** Recall from the lectures that the BLP has two key properties: (1) $E[e] = 0$ and (2) $E[e \times X] = 0$. Verify these properties for your multivariate model from Problem 3:

```{r 4a-code, eval=FALSE}
# Calculate residuals
residuals <- residuals(turnout_multivariate)

# Property 1: Mean of residuals
mean_residual <- mean(residuals)
cat("Mean of residuals:", mean_residual, "\n")

# Property 2: Correlation of residuals with each predictor
cor_res_income <- cor(residuals, states_data$income_thousands, use = "complete.obs")
cor_res_relig <- cor(residuals, states_data$religiosity, use = "complete.obs")
cor_res_age <- cor(residuals, states_data$over64, use = "complete.obs")

cat("Correlation with income:", cor_res_income, "\n")
cat("Correlation with religiosity:", cor_res_relig, "\n")
cat("Correlation with age:", cor_res_age, "\n")
```

**4b.** The lecture slides show a 3D visualization of a multivariate regression plane. Create a similar visualization for your multivariate model, showing the relationship between any two predictors and the outcome:

```{r 4b-code, eval=FALSE}
# 3D visualization (choose two predictors)
library(plotly)

# Create prediction grid
income_seq <- seq(min(states_data$income_thousands), 
                  max(states_data$income_thousands), length.out = 20)
relig_seq <- seq(min(states_data$religiosity), 
                 max(states_data$religiosity), length.out = 20)

grid <- expand.grid(income_thousands = income_seq, 
                    religiosity = relig_seq,
                    over64 = mean(states_data$over64, na.rm = TRUE))

grid$pred_turnout <- predict(turnout_multivariate, newdata = grid)

# Create 3D plot
plot_ly() %>%
  add_trace(data = states_data, 
            x = ~income_thousands, y = ~religiosity, z = ~vep12_turnout,
            type = 'scatter3d', mode = 'markers',
            marker = list(size = 5, color = 'blue', opacity = 0.7),
            name = 'Actual Data') %>%
  add_trace(data = grid,
            x = ~income_thousands, y = ~religiosity, z = ~pred_turnout,
            type = 'mesh3d', opacity = 0.5, color = 'orange',
            name = 'Regression Plane') %>%
  layout(scene = list(
    xaxis = list(title = 'Income (thousands)'),
    yaxis = list(title = 'Religiosity'),
    zaxis = list(title = 'Voter Turnout (%)')
  ), title = 'Multivariate Regression Plane')
```

**Questions for 4:**
1. Do the residuals from your model satisfy the BLP properties? What might it mean if they don't?
2. Looking at the 3D visualization, how does the regression plane represent the BLP? How would this differ if the true CEF were non-linear?
3. Based on all your analyses, write a brief conclusion (3-4 sentences) about what affects voter turnout in U.S. states and how well linear regression captures these relationships.

